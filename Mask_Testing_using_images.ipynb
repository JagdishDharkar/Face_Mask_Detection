{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2487478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from imutils.video import VideoStream\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013663e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f2ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxtPath=os.path.sep.join([r'C:\\Users\\jagdi\\Downloads\\Mask/','deploy.prototxt'])\n",
    "weightsPath=os.path.sep.join([r'C:/Users/jagdi/Downloads/Mask/','res10_300x300_ssd_iter_140000.caffemodel'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db476328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jagdi\\\\Downloads\\\\Mask/\\\\deploy.prototxt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototxtPath\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f946a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/jagdi/Downloads/Mask/\\\\res10_300x300_ssd_iter_140000.caffemodel'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797cca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=cv2.dnn.readNet(prototxtPath,weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698f1f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.dnn.Net 000001AA63D96D10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4826f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(r'C:\\Users\\jagdi\\Downloads\\Mask\\mobilenet_v2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "019bd6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(r'C:\\Users\\jagdi\\Downloads\\Mask\\Example\\example\\ex_01.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71021043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 51,  46, 117],\n",
       "        [ 51,  47, 118],\n",
       "        [ 51,  46, 117],\n",
       "        ...,\n",
       "        [ 98, 105, 109],\n",
       "        [ 99, 104, 108],\n",
       "        [ 99, 104, 108]],\n",
       "\n",
       "       [[ 51,  47, 118],\n",
       "        [ 51,  47, 118],\n",
       "        [ 51,  47, 118],\n",
       "        ...,\n",
       "        [ 83,  87,  94],\n",
       "        [ 83,  83,  85],\n",
       "        [ 87,  85,  86]],\n",
       "\n",
       "       [[ 47,  44, 113],\n",
       "        [ 48,  45, 114],\n",
       "        [ 52,  48, 118],\n",
       "        ...,\n",
       "        [ 59,  60,  62],\n",
       "        [ 54,  54,  56],\n",
       "        [ 65,  67,  70]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 36,  29,  31],\n",
       "        [ 40,  35,  38],\n",
       "        [ 28,  22,  25],\n",
       "        ...,\n",
       "        [ 16,  14,  17],\n",
       "        [ 16,  14,  17],\n",
       "        [ 16,  14,  17]],\n",
       "\n",
       "       [[ 45,  41,  43],\n",
       "        [ 53,  40,  41],\n",
       "        [ 28,  22,  25],\n",
       "        ...,\n",
       "        [ 25,  20,  23],\n",
       "        [ 19,  16,  19],\n",
       "        [ 16,  14,  17]],\n",
       "\n",
       "       [[ 61,  45,  45],\n",
       "        [ 56,  40,  41],\n",
       "        [ 28,  22,  25],\n",
       "        ...,\n",
       "        [ 17,  15,  18],\n",
       "        [ 16,  14,  17],\n",
       "        [ 16,  14,  17]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47362ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(h,w)=image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "557f970b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "394848ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=cv2.dnn.blobFromImage(image,1.0,(300,300),(104.0,177.0,123.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd7d437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -53.,  -53.,  -53., ...,   14.,    1.,   -9.],\n",
       "         [ -55.,  -50.,  -49., ...,  -13.,  -28.,  -38.],\n",
       "         [ -61.,  -48.,  -48., ...,  -30.,  -42.,  -56.],\n",
       "         ...,\n",
       "         [ -67.,  -88.,  -71., ...,  -88.,  -88.,  -88.],\n",
       "         [ -61.,  -87.,  -69., ...,  -88.,  -88.,  -87.],\n",
       "         [ -48.,  -84.,  -68., ...,  -88.,  -88.,  -88.]],\n",
       "\n",
       "        [[-130., -131., -131., ...,  -57.,  -68.,  -78.],\n",
       "         [-132., -127., -126., ...,  -85.,  -99., -111.],\n",
       "         [-137., -125., -126., ..., -102., -113., -130.],\n",
       "         ...,\n",
       "         [-147., -163., -151., ..., -163., -163., -163.],\n",
       "         [-141., -163., -150., ..., -163., -163., -163.],\n",
       "         [-136., -160., -149., ..., -163., -163., -163.]],\n",
       "\n",
       "        [[  -5.,   -6.,   -6., ...,    0.,  -11.,  -20.],\n",
       "         [  -8.,   -4.,   -3., ...,  -28.,  -40.,  -55.],\n",
       "         [ -17.,   -8.,   -3., ...,  -42.,  -58.,  -72.],\n",
       "         ...,\n",
       "         [ -90., -106.,  -95., ..., -106., -106., -106.],\n",
       "         [ -85., -106.,  -93., ..., -106., -106., -106.],\n",
       "         [ -81., -104.,  -93., ..., -106., -106., -106.]]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4490b1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 300, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fa6341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "detections=net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31d427d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 1.        , 0.9015393 , ..., 0.35069847,\n",
       "          0.8943858 , 0.52013457],\n",
       "         [0.        , 1.        , 0.8833362 , ..., 0.31085664,\n",
       "          0.5540466 , 0.46340668],\n",
       "         [0.        , 1.        , 0.79707986, ..., 0.4063273 ,\n",
       "          0.4787544 , 0.5570959 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f667ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over the detections\n",
    "for i in range(0,detections.shape[2]):\n",
    "    confidence=detections[0,0,i,2]\n",
    "    \n",
    "    \n",
    "    if confidence>0.5:\n",
    "        #we need the X,Y coordinates\n",
    "        box=detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "        (startX,startY,endX,endY)=box.astype('int')\n",
    "        \n",
    "        #ensure the bounding boxes fall within the dimensions of the frame\n",
    "        (startX,startY)=(max(0,startX),max(0,startY))\n",
    "        (endX,endY)=(min(w-1,endX), min(h-1,endY))\n",
    "        \n",
    "        \n",
    "        #extract the face ROI, convert it from BGR to RGB channel, resize it to 224,224 and preprocess it\n",
    "        face=image[startY:endY, startX:endX]\n",
    "        face=cv2.cvtColor(face,cv2.COLOR_BGR2RGB)\n",
    "        face=cv2.resize(face,(224,224))\n",
    "        face=img_to_array(face)\n",
    "        face=preprocess_input(face)\n",
    "        face=np.expand_dims(face,axis=0)\n",
    "        \n",
    "        (mask,withoutMask)=model.predict(face)[0]\n",
    "        \n",
    "        #determine the class label and color we will use to draw the bounding box and text\n",
    "        label='Mask' if mask>withoutMask else 'No Mask'\n",
    "        color=(0,255,0) if label=='Mask' else (0,0,255)\n",
    "        \n",
    "        #include the probability in the label\n",
    "        label=\"{}: {:.2f}%\".format(label,max(mask,withoutMask)*100)\n",
    "        \n",
    "        #display the label and bounding boxes\n",
    "        cv2.putText(image,label,(startX,startY-10),cv2.FONT_HERSHEY_SIMPLEX,0.45,color,2)\n",
    "        cv2.rectangle(image,(startX,startY),(endX,endY),color,2)\n",
    "        \n",
    "        \n",
    "        \n",
    "cv2.imshow(\"OutPut\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3017f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3e9c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
